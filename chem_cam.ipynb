{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from functools import partial\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from neural_nets.MLP import *\n",
    "from neural_nets.CNN import * \n",
    "\n",
    "from inference.bnn import *\n",
    "import inference.guides as guides\n",
    "import inference.likelihoods as likelihoods\n",
    "import inference.priors as priors\n",
    "from inference.util import *\n",
    "\n",
    "import examples.helpers as helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.load('examples/data/Y.pt').float()\n",
    "X = torch.load('examples/data/X.pt').float()\n",
    "targets_idx = torch.load('examples/data/targets_idx.pt')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test set indices by randomly selecting 20% of the unique targets\n",
    "test_idx = helpers.get_test_idx(targets_idx, 0.2, seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply to Y a linear transformation proposed by Smithson and Verkuilen (2006), so that our response variable is bounded away from zero:\n",
    "$$ \\tilde Y = \\frac{Y(N-1) + 1/K}{N} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N,K = Y.shape\n",
    "Y_tilde = (Y*(N-1) + 1/K)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split X and Y_tilde into train and test\n",
    "X_train = X[~test_idx]\n",
    "Y_tilde_train = Y_tilde[~test_idx]\n",
    "\n",
    "X_test = X[test_idx]\n",
    "Y_tilde_test = Y_tilde[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer perceptron\n",
    "We use principal components of the spectra as predictors, a Dirichlet likelihood on the data, and a MLP as neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.99\n",
    "\n",
    "pc = PCA(n_components=1000, whiten=True)\n",
    "pc = pc.fit(X_train)\n",
    "ncomp = np.where(np.cumsum(pc.explained_variance_ratio_)>threshold)[0][0]\n",
    "print(f'{ncomp} many components explain {threshold*100}% of the variance in the training set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = PCA(n_components=ncomp, whiten=True)\n",
    "\n",
    "Phi_train = torch.tensor(pc.fit_transform(X_train)).float()\n",
    "Phi_test = torch.tensor(pc.transform(X_test)).float()\n",
    "\n",
    "# create data loader\n",
    "train_data = TensorDataset(Phi_train,Y_tilde_train)\n",
    "test_data = TensorDataset(Phi_test,Y_tilde_test)\n",
    "\n",
    "batchsize = 32\n",
    "train_loader = DataLoader(train_data, batch_size = batchsize,\n",
    "                            shuffle = True)  \n",
    "test_loader = DataLoader(test_data, batch_size = batchsize,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp = .01\n",
    "N_train,d = Phi_train.shape\n",
    "\n",
    "net = MLP(in_dim=d, out_dim=K, width=10, depth=2, activation=\"relu\").to(device)\n",
    "likelihood = likelihoods.Dirichlet(N_train, alternative_param=False)\n",
    "prior = priors.IIDPrior((dist.Normal(torch.tensor(0.,device=device), torch.tensor(wp ** -0.5, device=device))))\n",
    "bayesian_mlp = LaplaceBNN(net, prior, likelihood, approximation='subnet', S_perc=0.3, name=\"mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP training\n",
    "# optim = pyro.optim.ClippedAdam({\"lr\": 1e-1, \"clip_norm\": 100.0, \"lrd\": 0.9999})\n",
    "optim = pyro.optim.ClippedAdam({\"lr\": 1e-2})\n",
    "epochs = 200\n",
    "nll_hist, nll_hist_test = bayesian_mlp.fit(train_loader, optim, epochs, num_particles=1, closed_form_kl=True, hist=True, test_loader=test_loader, test_eval_interval=1)\n",
    "helpers.plot_nll(nll_hist.detach(), nll_hist_test.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_predictions = bayesian_mlp.predict(Phi_test, num_predictions=100)\n",
    "y_predictions = bayesian_mlp.likelihood.sample(f_predictions)\n",
    "\n",
    "helpers.plot_predictions(y_predictions, Y_tilde_test, title='Linearized Laplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_mean = bayesian_mlp.likelihood._point_predictions(f_predictions).mean(axis=0) # rao blackwellized predictive mean\n",
    "(predictive_mean.cpu() - Y_tilde_test).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictive(input_data, num_samples=1):\n",
    "    y_predictions = bayesian_mlp.likelihood.sample(bayesian_mlp.predict(input_data, num_predictions=num_samples))\n",
    "    return y_predictions\n",
    "\n",
    "cp_train, cp_test = helpers.coverage(predictive, Phi_test, Y_tilde_test, Phi_train, Y_tilde_train, M=100)\n",
    "\n",
    "print('Train coverage by output dimension:', cp_train)\n",
    "print('Test coverage by output dimension:', cp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_mlp.log_marginal_likelihood(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(X_train,Y_tilde_train)\n",
    "test_data = TensorDataset(X_test,Y_tilde_test)\n",
    "\n",
    "batchsize = 32\n",
    "train_loader = DataLoader(train_data, batch_size = batchsize,\n",
    "                            shuffle = True)  \n",
    "batchsize_test = 32                                   \n",
    "test_loader = DataLoader(test_data, batch_size=batchsize_test, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train,d = X_train.shape\n",
    "\n",
    "ch_sizes = [9,9,1]\n",
    "krnl_sizes = [41,41,41]\n",
    "stride = [4,4,4]\n",
    "\n",
    "hf_size = d\n",
    "for i in range(len(ch_sizes)):\n",
    "    hf_size = (hf_size - krnl_sizes[i])//stride[i] + 1\n",
    "print(f\"Hidden feature size: {hf_size}\")\n",
    "cnn = CNN(in_dim=d, out_dim=K, ch_sizes=ch_sizes, krnl_sizes=krnl_sizes, stride=stride, lin_width=hf_size, lin_depth=1,).to(device)\n",
    "p = sum(p.numel() for p in cnn.parameters())\n",
    "print(f\"Number of parameters: {p}, Number of hidden features: {hf_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp = 1.\n",
    "\n",
    "likelihood = likelihoods.Dirichlet(N_train, alternative_param=False)\n",
    "cnn_map = CNN(in_dim=d, out_dim=K, ch_sizes=ch_sizes, krnl_sizes=krnl_sizes, stride=stride, lin_width=hf_size, lin_depth=1,)\n",
    "prior = priors.IIDPrior((dist.Normal(torch.tensor(0.,device=device), torch.tensor(wp ** -0.5, device=device))))\n",
    "bayesian_cnn = LaplaceBNN(cnn, prior, likelihood, approximation='subnet', S_perc=0.1, name=\"cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP training\n",
    "# optim = pyro.optim.ClippedAdam({\"lr\": 1e-1, \"clip_norm\": 100.0, \"lrd\": 0.999})\n",
    "optim = pyro.optim.ClippedAdam({\"lr\": 1e-3})\n",
    "nll_hist = bayesian_cnn.fit(train_loader, optim, 500, num_particles=1, closed_form_kl=True, hist=True)\n",
    "helpers.plot_nll(nll_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_predictions = bayesian_cnn.predict(X_test, num_predictions=30)\n",
    "y_predictions = bayesian_cnn.likelihood.sample(f_predictions)\n",
    "\n",
    "helpers.plot_predictions(y_predictions, Y_tilde_test, title='Linearized Laplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_mean = bayesian_cnn.likelihood._point_predictions(f_predictions).mean(axis=0) # rao blackwellized predictive mean\n",
    "(predictive_mean.cpu() - Y_tilde_test).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictive(input_data, num_samples=1):\n",
    "    y_predictions = bayesian_cnn.likelihood.sample(bayesian_cnn.predict(input_data, num_predictions=num_samples))\n",
    "    return y_predictions\n",
    "\n",
    "cp_train, cp_test = helpers.coverage(predictive, X_test, Y_tilde_test, X_train, Y_tilde_train, M=30)\n",
    "\n",
    "print('Train coverage by output dimension:', cp_train)\n",
    "print('Test coverage by output dimension:', cp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_cnn.log_marginal_likelihood(train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
