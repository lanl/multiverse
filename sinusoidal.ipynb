{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from functools import partial\n",
    "\n",
    "from neural_nets.MLP import *\n",
    "from neural_nets.CNN import * \n",
    "\n",
    "from inference.bnn import *\n",
    "import inference.guides as guides\n",
    "import inference.likelihoods as likelihoods\n",
    "import inference.priors as priors\n",
    "from inference.util import *\n",
    "\n",
    "import examples.helpers as helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinusoidal output\n",
    "X_range = torch.linspace(-1.5,2.5,1000)\n",
    "Y_true = torch.sin(X_range*7)\n",
    "\n",
    "X_train = torch.cat((X_range[150:250], X_range[torch.randint(250,550,(20,)).sort().values], X_range[550:750]))\n",
    "\n",
    "# create data\n",
    "nprec = .1**-2\n",
    "Y_train = torch.sin(X_train*7) + nprec**(-1/2)*torch.randn(X_train.shape[0])\n",
    "\n",
    "plt.plot(X_train,Y_train,'o', color='black', markersize=2)\n",
    "plt.plot(X_range,Y_true, color='red', alpha=0.5)\n",
    "\n",
    "data = TensorDataset(X_train.unsqueeze(1),Y_train.unsqueeze(1))\n",
    "batchsize = 16\n",
    "train_loader = DataLoader(data, batch_size = batchsize, shuffle = True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linearized Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp = 1.\n",
    "n = X_train.shape[0]\n",
    "\n",
    "prior = priors.IIDPrior((dist.Normal(torch.tensor(0., device=device), torch.tensor(wp**-2, device=device))))\n",
    "likelihood = likelihoods.HomoskedasticGaussian(n, precision=nprec)\n",
    "net = MLP(in_dim=1, out_dim=1, width=10, depth=2, activation=\"tanh\").to(device)\n",
    "bayesian_mlp = LaplaceBNN(net, prior, likelihood, approximation='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP training\n",
    "optim = pyro.optim.ClippedAdam({\"lr\": 1e-1, \"clip_norm\": 100.0, \"lrd\": 0.9999})\n",
    "epochs = 10\n",
    "nll_hist = bayesian_mlp.fit(train_loader, optim, epochs, num_particles=1,closed_form_kl=True, hist=True)\n",
    "helpers.plot_nll(nll_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_predictions = bayesian_mlp.predict(X_range.unsqueeze(-1), num_predictions=100, aggregate=False)\n",
    "y_predictions = bayesian_mlp.likelihood._point_predictions(f_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.plot_1d_gaussian_preds(y_predictions,X_range, train_x=X_train, train_y=Y_train, precision=nprec,method_name='Linearized Laplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictive(input_data, num_samples=1):\n",
    "    y_predictions = bayesian_mlp.likelihood.sample(bayesian_mlp.predict(input_data, num_predictions=num_samples))\n",
    "    return y_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.coverage(predictive, x_test=X_range.unsqueeze(-1), y_test=Y_true, x_train=X_train.unsqueeze(-1), y_train=Y_train, M=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_mlp.log_marginal_likelihood(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(torch.arange(len(bayesian_mlp.GGN.diag())), 1/bayesian_mlp.GGN.diag(), color='black')\n",
    "plt.title('Posterior variance by parameter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamiltonian Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp = 1.\n",
    "nprec = .1**-2\n",
    "n = X_train.shape[0]\n",
    "\n",
    "prior = priors.IIDPrior((dist.Normal(torch.tensor(0., device=device), torch.tensor(wp ** -0.5, device=device))))\n",
    "likelihood = likelihoods.HomoskedasticGaussian(n, precision=nprec)\n",
    "kernel = pyro.infer.mcmc.NUTS\n",
    "net = MLP(in_dim=1, out_dim=1, width=10, depth=2, activation=\"tanh\").to(device)\n",
    "hmc_mlp = MCMC_BNN(net, prior, likelihood, kernel_builder=kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_steps = 50\n",
    "num_samples = 50\n",
    "num_chains = 1\n",
    "\n",
    "mcmc = hmc_mlp.fit(train_loader, num_samples=num_samples, batch_data=True, warmup_steps=warmup_steps, num_chains = num_chains, disable_progbar=False).get_samples()\n",
    "pred = hmc_mlp.predict(X_range.unsqueeze(-1),num_predictions=10, aggregate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.plot_1d_gaussian_preds(pred,X_range, train_x=X_train, train_y=Y_train, precision=nprec,method_name='HMC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = helpers.samples_to_tensor(mcmc)\n",
    "M = weights.shape[0]\n",
    "# pick three posterior samples of weights\n",
    "weights_for_plot = weights[[0, M//2, M-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.loss_on_2d_subspace(train_loader, hmc_mlp, weights_for_plot, MC_chains=weights.unsqueeze(0), resolution=50, l_lim= -5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
